\documentclass[a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{latexsym}
\usepackage[english]{babel}
\usepackage[a4paper]{geometry}
\usepackage[sumlimits]{amsmath}
\usepackage{amssymb}
\usepackage[nomessages]{fp}
\usepackage{pst-all}
\usepackage[labelformat=simple]{caption}
\usepackage{multido}
\usepackage[normalem]{ulem}

\parindent0pt

\title{Math}
\author{Friedemann Zintel}
\date{\today}

\newcommand{\spc}{\hspace{0.2cm}}
\newcommand*{\vecdd}[2]{\begin{pmatrix}#1\\#2\\\end{pmatrix}}

\begin{document}
\tableofcontents
\newpage
\section{Orthogonality and determinant}
\subsection*{Orthogonality}
To proove: $\vec{v_1}\perp \vec{v_2} <=> \vec{v_1}*\vec{v_2}=0$ :\\\\
Be $\vec{v_1}=\vecdd{x_1}{y_1}=|\vec{v_1}|\vecdd{\cos\alpha}{\sin\alpha}$, $\vec{v_2}=\vecdd{x_2}{y_2}=|\vec{v_2}|\vecdd{\cos\beta}{\sin\beta}$
with $\alpha=\measuredangle\vec{v_1}$, $\beta=\measuredangle\vec{v_2}$
\\\\\\\\
$\vec{v_1}*\vec{v_2}
=|\vec{v_1}|\vecdd{\cos\alpha}{\sin\alpha}|\vec{v_2}|\vecdd{\cos\beta}{\sin\beta}
=|\vec{v_1}||\vec{v_2}|(\cos\alpha\cos\beta+\sin\alpha\sin\beta)=\uuline{|\vec{v_1}||\vec{v_2}|\cos(\alpha-\beta)}$.
\\\\\\\\
Be $\vec{v_1}\perp \vec{v_2} <=> \alpha=\beta+\frac{\pi}{2}$, w.l.o.g.
\\\\
$=>|\vec{v_1}||\vec{v_2}|\cos(\alpha-\beta)=|\vec{v_1}||\vec{v_2}|\cos(\beta+\frac{\pi}{2}-\beta)=0$
\\\\$\square$
\subsection*{Determinant}
Let's choose $\sin()$ instead of $\cos()$ in the above equation:
\\\\
$|\vec{v_1}||\vec{v_2}|\sin(\alpha-\beta)=|\vec{v_1}||\vec{v_2}|(\sin\alpha\cos\beta-\cos\alpha\sin\beta)$
\\\\
$=|\vec{v_1}||\vec{v_2}|\vecdd{\sin\alpha}{\cos\alpha}\vecdd{\cos\beta}{-\sin\beta}$
$=\vecdd{|\vec{v_1}|\sin\alpha}{|\vec{v_1}|\cos\alpha}\vecdd{|\vec{v_2}|\cos\beta}{-|\vec{v_2}|\sin\beta}=\vecdd{y_1}{x_1}\vecdd{x_2}{-y_2}$
\\\\
$=\det\left(\begin{array}{ll}x_2&x_1\\y_2&y_1\\\end{array}\right)=\uuline{\det\left(\begin{array}{ll}\vec{v_2}&\vec{v_1}\\\end{array}\right)}.$
\\\\\\
If $\alpha=\beta+k*\pi$, w.l.o.g, $k\in\mathbb{N}$
\\\\
$=> \det\left(\begin{array}{ll}\vec{v_2}&\vec{v_1}\\\end{array}\right)=|\vec{v_1}||\vec{v_2}|\sin(\alpha-\beta)=|\vec{v_1}||\vec{v_2}|\sin(\beta+k*\pi-\beta)=0$
\\\\
$=> \vec{v_1}$ and $\vec{v_2}$ are linear dependent and the determinant in general determines linear dependency.
\newpage
\section{Law of cosines}
To proove: $c^2 = a^2+b^2-2ab\cos\gamma$
\\\\\\
$\gamma>=\frac{\pi}{2}:$
\begin{align}
d^2=b^2-e^2\\
e=b\sin(\pi-\gamma)\\
1=\sin^2\gamma+\cos^2\gamma
\end{align}
\\\\
\begin{align*}
c^2 = (a+d)^2+e^2
\\\\
=(a+\sqrt{b^2-e^2})^2+e^2
\\\\
=a^2+2a\sqrt{b^2-e^2}+b^2
\\\\
=a^2+2a\sqrt{b^2-b^2\sin^2(\pi-\gamma)}+b^2
\\\\
=a^2+2ab\sqrt{1-\sin^2(\pi-\gamma)}+b^2
\\\\
=a^2+2ab\sqrt{\cos^2(\pi-\gamma)}+b^2
\\\\
=a^2+b^2+2ab\cos(\pi-\gamma)
\\\\
=a^2+b^2-2ab\cos\gamma
\end{align*}
\\\\
$\square$
\newpage
\section{Polynomial derivation}
To proove: $(x^n)' = nx^{n-1}$
\\\\\\
\begin{align*}
\frac{f(x+\vartriangle x)-f(x)}{\vartriangle x}
\\\\
=\frac{(x+\vartriangle x)^n-x^n}{\vartriangle x}
\\\\
=\frac{\sum_{k=0}^{n}{n \choose k }(x^{n-k}\vartriangle x^k)-x^n}{\vartriangle x}
\\\\
=\frac{x^n\Delta x^0+\sum_{k=1}^{n}{n \choose k}(x^{n-k}\Delta x^k)-x^n}{\Delta x}
\\\\
=\frac{\sum_{k=1}^{n}{n \choose k}(x^{n-k}\Delta x^k)}{\Delta x}
\\\\
=\frac{\Delta x\sum_{k-1}^{n}{n \choose k}(x^{n-k}\Delta x^{k-1})}{\Delta x}
\\
=\sum_{k-1}^{n}{n \choose k}(x^{n-k}\Delta x^{k-1})
\\\\
=\sum_{k=1}^{n}\frac{n!}{k!(n-k)!}(x^{n-k}\Delta x^{k-1})
\\\\
=nx^{n-1}+\sum_{k=2}^{n}{n \choose k}(x^{n-k}\Delta x^k)
\\\\
\lim_{\Delta x \to 0}\left(nx^{n-1}+\sum_{k=2}^{n}{n \choose k}(x^{n-k}\Delta x^k)\right) = nx^{n-1}
\end{align*}
\\\\
$\square$
\newpage
\section{Binomial theorem}
To proove: $(x+y)^n=\sum_{k=0}^{n}{n \choose k}(x^{n-k}y^k)$
\\\\
Induction:\\
$n=0$:
\begin{align*}
(x+y)^0=1=\sum_{k=0}^{0}{0 \choose k}(x^{0-k}y^k)
\end{align*}
$n \to n+1$:
\begin{align*}
(x+y)^{n+1}=(x+y)^n(x+y)\stackrel{\textnormal{i.p.}}{=}\sum_{k=0}^{n}{n \choose k}(x^{n-k}y^{k})(x+y)
\\\\
=\sum_{k=0}^{n}{n \choose k}(x^{n+1-k}y^k)+\sum_{k=0}^{n}{n \choose k}(x^{n-k}y^{k+1})
\\\\
=\sum_{k=0}^{n}{n \choose k}(x^{n+1-k}y^k)+\sum_{k=1}^{n+1}{n \choose k-1}(x^{n+1-k}y^{k})
\\\\
={n \choose 0}x^{n+1}y^0+\sum_{k=1}^{n}{n \choose k}(x^{n+1-k}y^k)+{n \choose n}x^0y^{n+1}+\sum_{k=1}^{n}{n \choose k-1}(x^{n+1-k}y^k)
\\\\
={n+1 \choose 0}x^{n+1}y^0+\sum_{k=1}^{n}{n \choose k}(x^{n+1-k}y^k)+{n+1 \choose n+1}x^0y^{n+1}+\sum_{k=1}^{n}{n \choose k-1}(x^{n+1-k}y^k)
\\\\
={n+1 \choose 0}x^{n+1}y^0+\sum_{k=1}^{n}{n \choose k-1}(x^{n+1-k}y^k)+\sum_{k=1}^{n}{n \choose k}(x^{n+1-k}y^k)+{n+1 \choose n+1}x^0y^{n+1}
\\\\
=^*{n+1 \choose 0}x^{n+1}y^0+\sum_{k=1}^{n}\left({n \choose k-1}+{n \choose k}\right)(x^{n+1-k}y^k)+{n+1 \choose n+1}x^0y^{n+1}
\\\\
={n+1 \choose 0}x^{n+1}y^0+\sum_{k=1}^{n}{n+1 \choose k}(x^{n+1-k}y^k)+{n+1 \choose n+1}x^0y^{n+1}
\\\\
=\sum_{k=0}^{n+1}{n+1 \choose k}(x^{n+1-k}y^k)
\end{align*}
\\\\
$\square$
\newpage
\begin{align*}
^*
\\
{n \choose k-1}+{n \choose k}=\frac{n!}{(k-1)!(n-k+1)!}+\frac{n!}{k!(n-k)!}
\\\\
=\frac{n!k}{k!(n-k+1)!}+\frac{n!(n-k+1)}{k!(n-k+1)!}
\\\\
=\frac{n!k+n!(n-k+1)}{k!(n+1-k)!}
\\\\
=\frac{n!(k+n+1-k)}{k!(n+1-k)!}
\\\\
=\frac{(n+1)!}{k!(n+1-k)!}
\\\\
=\uuline{{n+1 \choose k}}
\end{align*}
\newpage
\section{Linear regression}
measured values $x_i,y_i$ $|$ $1<=i<=n, n\in \mathbb{N}$
\\\\
regression line: $y=mx+b$\\
minimize error by calculating least squares
\\\\
\begin{align*}
S=\sum_{i=1}^{n}(y_i-(mx_i+b))^2=\sum_{i=1}^{n}(y_i-mx_i-b)^2
\end{align*}
\\\\
set $\frac{\partial S}{\partial m}=0$ :
\begin{align*}
\frac{\partial S}{\partial m}=-2\sum_{i=1}^{n}(y_i-mx_i-b)x_i=0
\\\\
\Longleftrightarrow \quad 0=\sum_{i=1}^{n}(y_i-mx_i-b)x_i=\sum_{i=1}^{n}(x_iy_i-mx_ix_i-bx_i)
\\\\
=\sum_{i=1}^{n}x_iy_i-m\sum_{i=1}^{n}x_ix_i-b\sum_{i=1}^{n}x_i \quad \textbf{: \rm I}
\end{align*}
\\\\
set $\frac{\partial S}{\partial b}=0$ :
\begin{align*}
\frac{\partial S}{\partial b}=-2\sum_{i=1}^{n}(y_i-mx_i-b)=0
\\\\
\Longleftrightarrow \quad 0=\sum_{i=1}^{n}(y_i-mx_i-b)=\sum_{i=1}^{n}(y_i-mx_i-b)=\sum_{i=1}^{n}y_i-m\sum_{i=1}^{n}x_i-nb
\\\\
\Longleftrightarrow \quad b=\frac{1}{n}\sum_{i=1}^{n}y_i-m\frac{1}{n}\sum_{i=1}^{n}x_i=\uuline{y_M-mx_M} \quad \textbf{: \rm II}
\end{align*}
\rm{II} in \rm{I}:
\begin{align*}
0=\sum_{i=1}^{n}x_iy_i-m\sum_{i=1}^{n}x_ix_i-b\sum_{i=1}^{n}x_i=\sum_{i=1}^{n}x_iy_i-m\sum_{i=1}^{n}x_ix_i-(y_M-mx_M)\sum_{i=1}^{n}x_i
\\\\
=\sum_{i=1}^{n}x_iy_i-m\sum_{i=1}^{n}x_ix_i-y_M\sum_{i=1}^{n}x_i+mx_M\sum_{i=1}^{n}x_i
\\\\
\Longleftrightarrow \quad m\left(\sum_{i=1}^{n}x_ix_i-x_M\sum_{i=1}^{n}x_i\right)=\sum_{i=1}^{n}x_iy_i-y_M\sum_{i=1}^{n}x_i
\\\\
\Longleftrightarrow \quad m=\frac{\sum_{i=1}^{n}x_iy_i-y_M\sum_{i=1}^{n}x_i}{\sum_{i=1}^{n}x_ix_i-x_M\sum_{i=1}^{n}x_i}
\\\\
=\frac{\frac{1}{n}\sum_{i=1}^{n}x_iy_i-x_My_M}{\frac{1}{n}\sum_{i=1}^{n}x_ix_i-x_Mx_M}
\\\\
=^*\uuline{\frac{Cov(x,y)}{Var(x)}}
\\\\\\\\
\Longrightarrow y=mx+n
\\\\
=\frac{Cov(x,y)}{Var(x)}x+(y_M-\frac{Cov(x,y)}{Var(x)}x_M)
\\\\
=\uuline{\frac{Cov(x,y)}{Var(x)}(x-x_M)+y_M}
\end{align*}
\newpage
\begin{align*}
^*
\\\\
Cov(x,y):=\frac{1}{n}\sum_{i=1}^{n}(x_i-x_M)(y_i-y_M)
\\
Var(x):=\frac{1}{n}\sum_{i=1}^{n}(x_i-x_M)^2=Cov(x,x)
\\\\
Cov(x,y):=\frac{1}{n}\sum_{i=1}^{n}(x_i-x_M)(y_i-y_M)
\\\\
=\frac{1}{n}\sum_{i=1}^{n}(x_iy_i-x_iy_M-x_My_i+x_My_M)
\\\\
=\frac{1}{n}\left(\sum_{i=1}^{n}x_iy_i-y_M\sum_{i=1}^{n}x_i-x_M\sum_{i=1}^{n}y_i+nx_My_M\right)
\\\\
=\frac{1}{n}\sum_{i=1}^{n}x_iy_i-y_Mx_M-x_My_M+x_My_M
\\\\
=\uuline{\frac{1}{n}\sum_{i=1}^{n}x_iy_i-x_My_M}
\end{align*}
\newpage
\section{linear interpolation of discrete vector field}
Be $\vec{g}:\mathbb{Z}^n\rightarrow\mathbb{R}^m$\\\\
We define $\vec{f}:\mathbb{R}^n\rightarrow\mathbb{R}^m$ as:\\\\
\begin{align*}
  \vec{f}(\vec{v}):=\sum_{p\in\mathcal{P}(dim)}^{}\prod_{i=1}^{n}\left((1-d_{v_i})^{1-\delta_p(i)}d_{v_i}^{\delta_p(i)}\right)\vec{g}(\vec{v}_p)
\end{align*}
With
\begin{align*}
  dim:=\{x \mid 1\leq x\leq n\},\quad p\in\mathcal{P}(dim)\\\\
  \delta_p:\mathbb{N}\rightarrow\{0,1\}\\
  \delta_p(x):=
  \begin{cases}
    1&x\in p\\
    0&x\not\in p
  \end{cases}\\\\
  \vec{v}_p:v_{p_i}:=
  \begin{cases}
    \lceil v_i\rceil&i\in p\\
    \lfloor v_i\rfloor&i\not\in p
  \end{cases}\\\\
  \vec{d}_{\vec{v}}:=\vec{v}-\vec{v}_{\emptyset}
\end{align*}
\end{document}
